# ZeroBot: Local LLM Chatbot (1-Hour RAG Build)

A 100% offline RAG-based chatbot built in 1 hour using Ollama, Streamlit, LangChain, and ChromaDB. No cloud. No API keys. No BS.

## ğŸ”„ Ollama Model Auto-Pull

ZeroBot uses a custom Ollama Docker image that auto-pulls the model (default: `gemma:2b`) at container start.

### How it works

- Entrypoint pulls model before Ollama server runs
- `OLLAMA_MODEL` env var defines the model
- Docker Compose builds Ollama from the custom image

### Run

```bash
docker compose build ollama
docker compose up -d
```

````

---

## ğŸš€ Features (Pareto-Optimized)

- ğŸ§  Local LLM (Mistral, LLaMA2) via Ollama
- ğŸ•¸ Web ingestion via Playwright + Unstructured
- ğŸ§© RAG pipeline using LangChain + ChromaDB
- ğŸ’» Streamlit-based UI
- ğŸ§± Fully dockerized, one-liner setup

## ğŸ—ï¸ System Architecture

```
User â‡„ Streamlit â‡„ Ollama â‡„ ChromaDB
                     â‡‘
          Playwright + Unstructured
```

## âš™ï¸ Stack

- LLM: Ollama (`mistral`, `llama2`, `gemma`)
- RAG: LangChain + ChromaDB
- Crawler: Playwright + Unstructured
- UI: Streamlit
- Infra: Docker Compose

## âš¡ Quickstart

```bash
git clone https://github.com/yourusername/zerobot.git
cd zerobot
docker compose up --build
```

- First run pulls LLM model
- Visit: [http://localhost:8501](http://localhost:8501)

## ğŸŒ Crawling Docs

Edit `src/crawler/crawler.py` â†’ update `URLS` list to your target sites. On startup, it auto-ingests into ChromaDB.

## ğŸ’¬ Sample Usage

```txt
User: What is a Python list comprehension?
ZeroBot: [Uses local docs + LLM to answer]
```

## ğŸ“ Folder Structure

```
zerobot/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ readme.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â””â”€â”€ crawler/
â””â”€â”€ data/ (persistent vector store)
```

## ğŸ‘¨â€ğŸ’» Dev Notes

- Change `OLLAMA_MODEL` to try other LLMs
- Extend Streamlit or crawler logic freely
- Pareto tip: tweak crawler before tuning model

## ğŸ“ License

MIT. Open to hacks and PRs.
````
